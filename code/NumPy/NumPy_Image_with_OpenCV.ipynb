{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab079de-b33a-4934-8350-44aa60c2fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f978f4-9f61-4531-abfc-5a66e8347fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy + OpenCV\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image (BGR format)\n",
    "img = cv2.imread('people.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0239b0d-202f-4408-87b6-58fc9d1e2be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (565, 735, 3)\n",
      "Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", img.shape)     # (height, width, channels)\n",
    "print(\"Type:\", type(img))     # <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5585cb57-311c-4bff-b48a-13771e6ff847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixels: 158 185 222\n"
     ]
    }
   ],
   "source": [
    "# Access pixel at row=100, col=50\n",
    "(b, g, r) = img[100, 50]\n",
    "print(\"Pixels:\", b, g, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90929dec-0a0b-4841-8a24-791a8c3046a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change a pixel\n",
    "img[100, 50] = [0, 0, 255]   # Set to Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebf79d3-bbac-41b9-875e-2b1411f36907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop region\n",
    "crop = img[50:200, 100:300]\n",
    "cv2.imshow(\"Crop\", crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1078a4-4613-4d97-a87f-920809c9f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a65eb7-a0dd-4c34-bca2-2f97591cba23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96947dd7-67c7-4dfc-bc13-525130886041",
   "metadata": {},
   "source": [
    "### NumPy Operations on Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b10208-ed84-46b6-a60d-ab1472183cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase brightness\n",
    "bright = np.clip(img + 50, 0, 255)\n",
    "\n",
    "# Invert colors\n",
    "invert = 255 - img\n",
    "\n",
    "# Masking\n",
    "mask = gray > 100\n",
    "img[mask] = [255, 255, 255]\n",
    "\n",
    "cv2.imshow(\"bright\", bright)\n",
    "cv2.imshow(\"invert\", invert)\n",
    "cv2.imshow(\"Gray\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d38d4-c180-46c3-96ea-0b76e58dae16",
   "metadata": {},
   "source": [
    "## Complete Working Example.\n",
    "Original -> Brightened -> Inverted -> Masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5da5d0-1f6f-460a-abea-15a929e500dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image (make sure you have a file named 'image.jpg' in the same folder)\n",
    "img = cv2.imread('people.jpg')\n",
    "\n",
    "# Convert to grayscale for masking\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1️⃣ Brighten the image\n",
    "bright = np.clip(img + 50, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 2️⃣ Invert colors\n",
    "invert = 255 - img\n",
    "\n",
    "# 3️⃣ Mask bright areas\n",
    "mask = gray > 100\n",
    "masked = img.copy()\n",
    "masked[mask] = [255, 255, 255]\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Brightened', bright)\n",
    "cv2.imshow('Inverted', invert)\n",
    "cv2.imshow('Masked', masked)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee8cb4-04fd-45c7-8234-5bc3e4a485de",
   "metadata": {},
   "source": [
    "### Same example, but all 4 images in a single window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f8ba36-9723-40ac-b10f-963d034efb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread('people.jpg')\n",
    "\n",
    "# Resize for consistent display\n",
    "img = cv2.resize(img, (300, 300))\n",
    "\n",
    "# Convert to grayscale for masking\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1️⃣ Brighten the image\n",
    "bright = np.clip(img + 50, 0, 255).astype(np.uint8)\n",
    "#bright = np.clip(img + 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 2️⃣ Invert colors\n",
    "invert = 255 - img\n",
    "\n",
    "# 3️⃣ Mask bright areas\n",
    "mask = gray > 100\n",
    "masked = img.copy()\n",
    "masked[mask] = [255, 255, 255]\n",
    "\n",
    "# Add labels to each image (for clarity)\n",
    "def add_label(image, text):\n",
    "    labeled = image.copy()\n",
    "    cv2.putText(labeled, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "    return labeled\n",
    "\n",
    "img_labeled = add_label(img, 'Original')\n",
    "bright_labeled = add_label(bright, 'Brightened')\n",
    "invert_labeled = add_label(invert, 'Inverted')\n",
    "masked_labeled = add_label(masked, 'Masked')\n",
    "\n",
    "# Combine images in a 2x2 grid\n",
    "top_row = cv2.hconcat([img_labeled, bright_labeled])\n",
    "bottom_row = cv2.hconcat([invert_labeled, masked_labeled])\n",
    "combined = cv2.vconcat([top_row, bottom_row])\n",
    "\n",
    "# Show all together\n",
    "cv2.imshow('Image Processing Comparison', combined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afa7b4-584e-408f-b30e-373b56fecb1f",
   "metadata": {},
   "source": [
    "## Another sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832b7f4-0c7f-4a3e-a775-37d0314cc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Load the image\n",
    "#img = cv2.imread('cricket-batter.jpg')\n",
    "img = cv2.imread('people.jpg')\n",
    "print(\"Original shape:\", img.shape)   # (height, width, channels)\n",
    "\n",
    "# 2️⃣ Convert to Grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print(\"Gray shape:\", gray.shape)   # (height, width)\n",
    "\n",
    "# 3️⃣ Increase Brightness using NumPy\n",
    "# Add a constant value to every pixel\n",
    "bright = np.clip(gray + 50, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 4️⃣ Save the results\n",
    "cv2.imwrite('gray_image.jpg', gray)\n",
    "cv2.imwrite('bright_image.jpg', bright)\n",
    "\n",
    "# 5️⃣ Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Grayscale', gray)\n",
    "cv2.imshow('Brightened', bright)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4fa89b9-1c36-4909-aba0-8790962dc984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300)\n",
      "(300, 300, 3)\n",
      "Original pixel value: [255 253 251]\n",
      "Grayscale pixel value: 253\n",
      "Brightened pixel value: [254 252 250]\n"
     ]
    }
   ],
   "source": [
    "# Check pixel values.\n",
    "print(gray.shape)\n",
    "print(bright.shape)\n",
    "print(\"Original pixel value:\", img[100, 100])\n",
    "print(\"Grayscale pixel value:\", gray[100, 100])\n",
    "print(\"Brightened pixel value:\", bright[100, 100])\n",
    "#print(type(bright[100][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11d750-8b50-4cfd-b942-129e086fab67",
   "metadata": {},
   "source": [
    "# Example with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c8654-ac11-4081-b499-a06e07d9e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('people.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Image using NumPy + Matplotlib\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
